{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Mr. Narendra Damodardas Modi is the present and 15th Indian prime minister. He has been serving our nation since 26th May 2014. From the year 2001 to 2014, before taking over Delhi, he served the role of Honourable Chief Minister of Gujarat. He is a Member of the Parliament (MP), who represents the city of Varanasi. He is the leader of the popular Bharatiya Janata Party (BJP). \\n\\nIn the 2014 general election, BJP, led by Narendra Modi, gained the majority in the Lok Sabha. This was the first such major win for a political party since 1984. \\n\\n\\nAll About Narendra Modi\\nEarly Life \\nPrime Minister Narendra Modi was born in a lower-middle-class family at Vadnagar, Gujarat. He had a keen interest in politics since the early days of his childhood. After completing his higher education in his hometown, he decided to join Rashtriya Swayamsevak Sangh. This is popularly known as RSS in our country. During his earlier ages of life, he was headstrong and was not that keen on the concept of marriage. Since then, he has dedicated his entire life to his motherland. At the age of 17, Narendra Modi decided to travel around the country and gain knowledge while helping others. Mr Modi is a great admirer of the ideologies of Swami Vivekananda. \\n\\nHe always emphasizes, \"Coming age is the age of knowledge. However, rich, poor, or powerful a country be, if they want to move ahead, only knowledge can lead them to that path.\" \\n\\n \\n\\nThe Life Story \\nNarendra Modi is a motivation for every Indian. He became the prime minister of India after breaking the bar of a poverty-stricken tea-selling boy. He has seamlessly become a development-oriented leader. Narendra Damodardas Modi was born on 17th September 1950. He is a prominent figure who showed us success is not related to the caste system. It doesn’t matter from where a person belongs or what his or her background is. \\n\\nNarendra Modi is considered a master strategist and becomes a ray of hope for billions of lives in India. He is one of the leaders who stay focused on developments. With him, the dignity of labor is respected, and the working class is supported greatly. Narendra Modi is the glorious son of Late Damodardas Mulchand Modi and Heeraben Damodardas Modi. None of the prime ministers had taken office when their mother was alive. It is Mr. Modi who created history. \\n\\n \\n\\nEradicating Black Money from Our Country \\nDealing with strong hands, Narendra Modi has a significant role in eradicating black money from India. He demonetized the currency notes of 500 and 1000 rupees and later introduced a complete new semblance of Indian currency notes. This helped a lot in eliminating corruption, terrorism, and counterfeit currency from India. Our 15th Prime Minister is considered to be a stern administrator and leader with strict and protective discipline. These can be seen through his works, policies, speeches, and initiation of various schemes. He maintains a great image when it comes to rising from humble beginnings and moving to become the Prime Minister of India. \\n\\n \\n\\nCampaigns led by Modi \\nPoverty in a farmer\\'s life has been reduced to a great extent, thanks to the helping hands offered by our Prime Minister. Not only poor farmers, but he also helped reduce the poverty level from other sectors. He has eliminated the problem of water from India. Carrying the work to the next stage after Mr. Atal Vihari Vajpayee, Modi showed a great interest in the construction of infrastructure in India.  \\n\\nA generous and recognized campaign, \"Make in India,\" was started by Mr. Narendra Modi. In this campaign, he conveyed the message to manufacturers that it is best to use Indian materials and products rather than depending on foreign goods. This way, our money will circulate within the country and it will help to reduce the inflation rate. \\n\\nTo end with, India has benefitted like never before under the leadership of Honourable Prime Minister Mr Narendra Modi. He has taken all the initiatives to make our country great and appreciable on the global standard. \\n\\n \\n\\nRecent Endeavours of Narendra Modi  \\nIn April 2020, Narendra Modi, an Indian politician and the current Prime Minister of India, overtook US President Donald Trump as the most popular world leader on Facebook. He has ranked first among all international leaders in the fight against the Coronavirus (COVID-19) pandemic, ensuring the safety and security of Indian citizens and offering all essential help to other countries. \\n\\nIn the aftermath of the pandemic, Prime Minister Narendra Modi decided to create a distinct Ministry of AYUSH, now selling medications to other countries. \\n\\nArticle 370, which granted special status to the former state of Jammu and Kashmir (J&K), was repealed under his strong leadership. Narendra Modi\\'s leadership has been hailed by world leaders, international agencies, philanthropists, Nobel laureates, and many more. \\n\\nModiji earned the UN\\'s top environmental accolade, the Champion of the Earth, in October 2018. On February 22, 2019, Narendra Damodardas Modi was awarded the prestigious Seoul Peace Prize 2018 to contribute to international collaboration and global economic prosperity. On April 12, 2019, he was also awarded the Order of St. Andrew, Russia\\'s highest civilian decoration. \\n\\nFor his second term as Prime Minister of India, he ran on \"Nationalism\" in the 2019 general election and earned a large mandate. \\n\\n \\n\\nBenchmarks of Modi’s Success\\nAfter being elected to his second term as Gujarat\\'s chief minister in 2002, he focused on the state\\'s economic development and an attractive location for business people and industrialists. \\n\\nIn 2007, during his third term as CM, he increased agricultural growth rates, provided power to all villages, and bolstered the state\\'s rapid development. \\n\\nWhen he was Gujarat\\'s chief minister, he launched groundwater conservation initiatives with the government’s help. This aided in the cultivation of Bt cotton by providing irrigation through tube wells. \\n\\n Gujarat\\'s governor, Narendra Modi, has provided power to every village. In addition, he modified the state\\'s power distribution system by dividing agricultural and rural electricity. \\n\\nNarendra Modi introduced honouring the Interworldwidenational Day of Yoga during his speech to the United Nations General Assembly. Thanks to his efforts, the International Day of Yoga is observed on June 21st all over the world. \\n\\nModi\\'s book \\'Aankh Ka Dhanya Che\\' has a compilation of his poems. The Madame Tussauds Wax Museum in London has a wax statue of Modi. In 2015, he was placed sixth on Fortune magazine\\'s list of the world\\'s most powerful leaders. \\n\\nNarendra Modi was designated one of the top 30 most influential individuals on the Internet and one of Forbes\\' top ten most powerful people on the planet. He earned the United Nation’s highest environmental honor, \\'Champions of the Earth,\\' in October 2018. He is the first Indian to get the 2018 Seoul Peace Prize. \\n\\nHe is a beacon of hope for billions of Indians and one of the most popular leaders who focus on development. Even our Prime Minister Narendra Modi\\'s slogan, \"Main Bhi Chowkidar,\" emphasizes the dignity of labor and seeks the support of the working people. He used this term because he believes he, too, is standing steadfast and doing his job as the nation\\'s \"chowkidar.\" He further stated that any Indian fighting against corruption, filth, social evils, and other issues for India\\'s prosperity is a \\'Chowkidar.\\' The slogan \\'Main Bhi chowkidar\\' became famous as a result of this.', metadata={'source': 'speech.txt'})]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DATA INGESTION\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"speech.txt\")\n",
    "text_documents = loader.load()\n",
    "text_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### web based loader\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "### load, chunk, and index the content of the html page\n",
    "\n",
    "loader=WebBaseLoader(web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "                     bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "                         class_=(\"post-title\",\"post-content\",\"post-header\")\n",
    "\n",
    "                     )))\n",
    "\n",
    "text_documents=loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\\n\\nFig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.\\n\\nFig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)\\nChain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\\\{(x, y_i , r_i , z_i)\\\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\\\geq r_{n-1} \\\\geq \\\\dots \\\\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\\\tau_h = (x, z_i, y_i, z_j, y_j, \\\\dots, z_n, y_n)$, where $\\\\leq i \\\\leq j \\\\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.\\nTo avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens during training.\\nThe training dataset in their experiments is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.\\n\\nFig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\\nThe idea of CoH is to present a history of sequentially improved outputs  in context and train the model to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al. 2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where an algorithm is encapsulated in a long history-conditioned policy. Considering that an agent interacts with the environment many times and in each episode the agent gets a little better, AD concatenates this learning history and feeds that into the model. Hence we should expect the next predicted action to lead to better performance than previous trials. The goal is to learn the process of RL instead of training a task-specific policy itself.\\n\\nFig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search (MIPS)#\\nThe external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)\\u200b algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items are mapped to the same buckets with high probability, where the number of buckets is much smaller than the number of inputs.\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random projection trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input space into half and each leaf stores one data point. Trees are built independently and at random, so to some extent, it mimics a hashing function. ANNOY search happens in all the trees to iteratively search through the half that is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks where most nodes can be reached by any other nodes within a small number of steps; e.g. “six degrees of separation” feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target. When it can’t get any closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a large distance in the data space, and each move in the lower layers refines the search quality.\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization.\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector quantization. It quantizes a data point $x_i$ to $\\\\tilde{x}_i$ such that the inner product $\\\\langle q, x_i \\\\rangle$ is as similar to the original distance of $\\\\angle q, \\\\tilde{x}_i$ as possible, instead of picking the closet quantization centroid points.\\n\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\nComponent Three: Tool Use#\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools can significantly extend the model capabilities.\\n\\nFig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\nMRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of “expert” modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the “External APIs” section of Prompt Engineering.\\nChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\n(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\\nAPI-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\\n\\nFig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent’s tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API’s description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user’s requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\\n\\nCase Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\\n\\nOne interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\nBoiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\nFor example, when requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:\\n\\ninquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.\\n\\nThey also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\nFig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes\\n\\nCommands:\\n1. Google Search: \"google\", args: \"input\": \"<search>\"\\n2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n9. Read file: \"read_file\", args: \"file\": \"<file>\"\\n10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\\n15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\\n17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\\n19. Do Nothing: \"do_nothing\", args:\\n20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\\n\\nYou should only respond in JSON format as described below\\nResponse Format:\\n{\\n    \"thoughts\": {\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- short bulleted\\\\n- list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n        \"speak\": \"thoughts summary to say to user\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n}\\nEnsure the response can be parsed by Python json.loads\\nGPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:\\n\\nYou will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code’s language, and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the “entrypoint” file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.\\nPython toolbelt preferences:\\n\\npytest\\ndataclasses\\n\\n\\nConversatin samples:\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython toolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"\\n  },\\n #  … same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Assumptions:\\\\n1. Model: The model will contain the game\\'s data, such as level information, character states, and enemy positions.\\\\n2. View: The view will handle the game\\'s visuals, including rendering the game objects, backgrounds, and updating the display.\\\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model accordingly.\\\\n\\\\nWith these assumptions in mind, is there any specific aspect of the keyboard control implementation you would like me to clarify?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files are compatible with each other.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\"\\n  }\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\\n\\n\\nFinite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\\n\\nOr\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn & Labash. “Reflexion: an autonomous agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. “In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.” arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n[15] Li et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 (2023).\\n[16] Shen et al. “HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace” arXiv preprint arXiv:2303.17580 (2023).\\n[17] Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” arXiv preprint arXiv:2304.05376 (2023).\\n[18] Boiko et al. “Emergent autonomous scientific research capabilities of large language models.” arXiv preprint arXiv:2304.05332 (2023).\\n[19] Joon Sung Park, et al. “Generative Agents: Interactive Simulacra of Human Behavior.” arXiv preprint arXiv:2304.03442 (2023).\\n[20] AutoGPT. https://github.com/Significant-Gravitas/Auto-GPT\\n[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer\\n', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pdf reader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader=PyPDFLoader('machine_learning_tutorial.pdf')\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='  i \\n \\n \\n', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 0}),\n",
       " Document(page_content='  i \\n \\nAbout the T utorial  \\nToday’s Artificial Intelligence (AI) has far surpassed the hype of blockchain and quantum \\ncomputing. The developers now take advantage of this in creating new Machine Learning \\nmodels and to re -train the existing models for better performance and results.  \\nThis tutorial will give an introduction to machine learning and its implementation in \\nArtificial Intelligence.  \\nAudience  \\nThis tutorial has been prepared for professionals aspiring to learn the complete picture of \\nmachine learning and artificial intelligence . \\nThis tutorial caters the learning needs of  both the novice learners and experts , to help \\nthem understand the concepts and implementation of artificial intelligence . \\n \\nPrerequisites  \\nThe learners of this tutorial are expected to know the basics of Python pr ogramming. \\nBesides, they need to have a solid understanding of  computer programing and \\nfundamentals.  \\nIf you are new to this arena, we suggest you  pick up tutorials based on these concepts \\nfirst, before you embark on with Machine Learning.  \\n \\nCopyright & Disclaimer  \\n@Copyright 201 9 by Tutorials Point (I) Pvt. Ltd.     \\nAll the content and graphics published in this e -book are the property of Tutorials Point (I) \\nPvt. Ltd.  The user of this e -book is prohibited to reuse, retain, copy, distribute or republish \\nany contents or a part of contents of this e -book in any manner without written consent \\nof the publisher.   \\nWe strive to update the contents of our website and tutorials as timely and as precisely as \\npossible, however, the contents may contain inaccuracies or errors. Tutorials Point (I) Pvt. \\nLtd. provides no guarantee regarding the accuracy, timeliness or completeness of our \\nwebsite or its contents including this tutorial. If you discover any errors on our website or \\nin this tutorial, please notify us at contact@tutorialspoint.com  \\n  ', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 1}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  ii \\n \\nT able of Contents  \\nAbout the Tutorial  ................................ ................................ ................................ ................................  i \\nAudience  ................................ ................................ ................................ ................................ ...............  i \\nPrerequisites  ................................ ................................ ................................ ................................ .........  i \\nCopyright & Disclaimer  ................................ ................................ ................................ .........................  i \\nTabl e of Contents  ................................ ................................ ................................ ................................ . ii \\n1. MACHINE LEARNING – INTRODUCTION  ................................ ................................ ............  1 \\n2. MACHINE LEARNING – WHAT TODAY’S AI CAN DO ? ................................ .........................  2 \\nExample  ................................ ................................ ................................ ................................ ...............  2 \\n3. MACHINE LEARNING – TRADITIONAL AI  ................................ ................................ ...........  3 \\nStatistical Techniques  ................................ ................................ ................................ ..........................  3 \\n4. MACHINE LEARN ING – WHAT IS MACHIN E LEARNING?  ................................ ....................  4 \\n5. MACHINE LEARNING – CATEGORIES OF MACHINE  LEARNING  ................................ ..........  6 \\nSupervised Learning  ................................ ................................ ................................ .............................  7 \\nUnsupervised Learnin g ................................ ................................ ................................ ........................  8 \\nReinforcement Learning ................................ ................................ ................................ .......................  9 \\nDeep Learning  ................................ ................................ ................................ ................................ .... 10 \\nDeep Reinforcement Learn ing ................................ ................................ ................................ ...........  10 \\n6. MACHINE LEARNING – SUPERVISED LEARNING  ................................ ..............................  11 \\nAlgorithms for Supervised Learning  ................................ ................................ ................................ ... 11 \\nk-Nearest Neighbours  ................................ ................................ ................................ ........................  11 \\nDecision Trees  ................................ ................................ ................................ ................................ .... 13 \\nNaive Bayes  ................................ ................................ ................................ ................................ .......  14 \\n \\n ', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 2}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  iii \\n \\nLogistic Regres sion ................................ ................................ ................................ .............................  14 \\nSupport Vector Machines  ................................ ................................ ................................ ..................  15 \\n7. MACHINE LEARNING – SCIKIT -LEARN ALGORITH M ................................ .........................  16 \\n8. MACHINE LEARNING – UNSUPERVISED LEARNING  ................................ .........................  17 \\nAlgorithms for Unsupervised Learning  ................................ ................................ ...............................  17 \\n9. MACHINE LEARNING – ARTIFICIAL NEURAL NET WORKS  ................................ .................  19 \\nANN Architectures  ................................ ................................ ................................ .............................  20 \\n10. MACHINE LEARNING  – DEEP LEARNING  ................................ ................................ .........  22 \\nApplications  ................................ ................................ ................................ ................................ .......  22 \\nUntapped Opportunities of Deep Learning  ................................ ................................ ........................  22 \\nWhat is Required for Achieving More Using Deep Learning?  ................................ .............................  23 \\nDeep Learning - Disadvantages  ................................ ................................ ................................ ..........  23 \\n11. MACHINE LEARNING – SKILLS FOR MACHINE LE ARNING  ................................ ................  26 \\nNecessity of Various Skills of Machine Learning  ................................ ................................ .................  26 \\n12. MACHINE LEARNING – IMPLEMENTING MACHINE LEARNING  ................................ ........  29 \\nLanguage Choice  ................................ ................................ ................................ ................................  29 \\nIDEs ................................ ................................ ................................ ................................ ....................  29 \\nPlatforms  ................................ ................................ ................................ ................................ ...........  30 \\n13. MACHINE LEARNING – CONCL USION  ................................ ................................ .............  31 \\n \\n ', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 3}),\n",
       " Document(page_content='  1 \\n \\nToday’s A rtificial Intelligence (AI)  has far surpassed the hype of blockchain and quantum \\ncomputing. This is due to the fact that huge computing resources are easily available to \\nthe common man. The developers now take advantage of this in creating new Machine \\nLearning models and to re -train the existing models for better performance and results. \\nThe easy availability of High Performance Computing (HPC) has resulted in a sudden \\nincreased demand for IT professionals having Machine Learning skills.  \\nIn this tutorial, you will learn in detail about:  \\nWhat is the crux of machine learning ? \\n \\n\\uf0b7 What are the different types in machine learning?  \\n \\n\\uf0b7 What are the different algorithms available for developing machine learning \\nmodels?  \\n \\n\\uf0b7 What tools are available for developing these models?  \\n \\n\\uf0b7 What are the pro gramming language choices?  \\n \\n\\uf0b7 What platforms support development and deployment of Machine Learning \\napplications?  \\n \\n\\uf0b7 What IDEs (Integrated Development Environment) are available?  \\n \\n\\uf0b7 How to quickly upgrade your skills in this important area?  \\n  1. Machine Learning  – Introduction  ', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 4}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  2 \\n \\nWhen you tag a face in a Facebook photo, it is AI that is running behind the scene s and \\nidentif ying faces in a picture. Face tagging is now omnipresent in several applications that \\ndisplay pictures with human faces. Why just human faces? There are several applications \\nthat detect objects such as cats, dogs, bottles, cars, etc. We have autonomous cars \\nrunning on our roads that detect objects in real time to steer the car. When you travel, \\nyou use Google Directions  to learn the real -time traffic situations and follow the best path \\nsuggested by Google at that point of time. This is yet another implementatio n of object \\ndetection technique in real time.  \\nLet us consider the example of Google Translate  application that we typically use while \\nvisiting foreign countries. Google’s online translator app on your mobile helps you \\ncommunicate with the local people spe aking a language that is foreign to you.  \\nThere are several applications of AI that we use practically today. In fact, each one of us \\nuse AI in many parts of our lives , even without our knowledge . Today’s AI can perform \\nextremely complex jobs with a great accuracy and speed. Let us discuss an example of  \\ncomplex task to understand what capabilities are expected in an AI application that you \\nwould be developing today for your clients.  \\nExample  \\nWe all use Google Directions  during our trip anywhere in the city  for a daily commute or \\neven for inter -city travels. Google Directions application suggests the fastest path to our \\ndestination at that time instance. When we follow this path, we have observed that Google \\nis almost 100% right in its suggestions and we sav e our valuable time on the trip.  \\nYou can imagine the complexity involved in developing this kind of application cons idering \\nthat there are multiple paths to your destination and the application has to judge the traffic \\nsituation in every possible path to give you a travel time estimate for each such path. \\nBesides , consider the fact that Google Directions covers the entire globe. Undoubtedly, \\nlots of AI and Machine Learning techniques are in -use under the hoods of such applications.   \\nConsidering the contin uous demand for the development of such applications, you will now \\nappreciate why there is a sudden demand for IT professionals with AI skills . \\nIn our next chapter, we  will learn what it take s to develop AI programs.  \\n  2. Machine Learnin g – What  Today’s AI Can Do?  ', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 5}),\n",
       " Document(page_content=\"Machine Learning   \\n \\n \\n  3 \\n \\nThe journey of AI began in the 1950's when the computing power was a fraction of what \\nit is today. AI started out with the predictions made by the machine in a fashion a \\nstatistician does predictions using his calculator. Thus, the initial entire AI development \\nwas based mainly on statistical techniques.  \\nIn this chapter, l et us discuss in detail what  these statistical techniques  are. \\nStatistical T echniques  \\nThe development of today’s AI applications started with using the age -old tra ditional \\nstatistical techniques. You must have used straight -line interpolation in schools to predict \\na future value. There are several other such statistical techniques which are successfully \\napplied in developing so -called AI programs. We say “so -called”  because the AI programs  \\nthat we have today  are much more complex and use techniques far beyond the statistical \\ntechniques used by the early AI programs.  \\nSome of the  examples of statistical techniques that are used for developing AI applications \\nin those days and are still in practice are listed here:  \\n \\n\\uf0b7 Regression  \\n\\uf0b7 Classification  \\n\\uf0b7 Clustering  \\n\\uf0b7 Probability Theories  \\n\\uf0b7 Decision Trees  \\n \\nHere we  have listed only some  primary techniques that are enough to get you started on \\nAI without scaring you of the vastness that AI  demands. If you are developing AI \\napplications based on l imited data, you would be using these statistical techniques.  \\nHowever,  today the data is abundant. To analyze the kind of huge data that we possess \\nstatistical techniques are of not much help as the y have some limitations of their own. \\nMore advanced methods such as deep learning are hence developed to solve many \\ncomplex problems.  \\nAs we move ahead in this tutorial, we will  understand what Machine Learning  is and how \\nit is used for developing such complex AI applications.  \\n  3. Machine Learning – Traditional AI  \", metadata={'source': 'machine_learning_tutorial.pdf', 'page': 6}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  4 \\n \\nConsider the following figure that shows a plot of house prices versus its size in sq. ft.  \\n \\n \\n \\nAfter plotting various data points on the XY plot, we draw a best -fit line to do our \\npredictions for any other house given its size. You will feed the known data to the machine \\nand ask it to find the best fit line. Once the best fit line is found by the ma chine, you will \\ntest its suitability by feeding in a known house size, i.e. the Y -value in the above curve. \\nThe machine will now return the estimated X -value, i.e. the expected price of the house. \\nThe diagram can be extrapolated to find out the price of a house which is 3000 sq. ft. or \\neven larger. This is called regression in statistics. Particularly, t his kind of regression is \\ncalled linear regression as the relationship between X & Y data points is linear.  \\n 4. Machine Learning – What is Machine \\nLearning?  \\n', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 7}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  5 \\n \\nIn many cases , the relationship between the X  & Y data points may not be a straight line, \\nand it may be a curve with a complex equation. Your task would be now to find out the \\nbest fitting curve which can be extrapolated to predict the future values. One such \\napplication plot is shown in the figure b elow.  \\n \\n \\n \\nSource: \\nhttps://upload.wikimedia.or g/wikipedia/commons/c/c9/Segmented_linear_regression_graph_showing_yield_of\\n_mustard_plants_vs_soil_salinity_in_Haryana%2C_India%2C_1987%E2%80%931988.jpg  \\n \\nYou will use the statistical optimization techniques to find out the equation for the best fit \\ncurve h ere. And this is what exactly Machine Learning is about. You use known \\noptimization techniques to find the best solution to your problem.  \\n \\nNext,  let us look at the different categories of Machine Learning.  \\n  \\n', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 8}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  6 \\n \\nMachine Learning is broadly categorized under the following headings:  \\n \\n \\nMachine learning evolved from left to right as shown in the above diagram.  \\n\\uf0b7 Initially, researchers started out with Supervised Learning. This is the case of \\nhousing price prediction discussed earlier.  \\n \\n\\uf0b7 This was followed by unsupervised learning, where the machine is made to learn \\non its own without any supervision.  \\n \\n\\uf0b7 Scientists discovered further that it may be a good idea to reward the machine \\nwhen it does the job the expected way and there came the Reinforcement Learning.  \\n \\n\\uf0b7 Very soon, the data that is available these days has become so humongous that \\nthe conventional techniques developed so far failed to analyze the big data and \\nprovide us the predictions.  \\n \\n\\uf0b7 Thus, came the deep learning where the human brain is simulated in t he Artificial \\nNeural Networks (ANN) created in our binary computers.  \\n \\n\\uf0b7 The machine now learns on its own using the high computing power and huge \\nmemory resources that are available today.  \\n \\n\\uf0b7 It is now observed that Deep Learning has solved many of the previo usly unsolvable \\nproblems.  \\n \\n\\uf0b7 The technique is now further advanced by giving incentives to Deep Learning \\nnetworks as awards and there finally comes Deep Reinforcement Learning.  \\n 5. Machine Learning – Categories of Machine \\nLearn ing \\n', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 9}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  7 \\n \\nLet us now study  each of these categories in more detail.  \\nSupervised Learning  \\nSupervised learning is analogous to  training a child to walk. You will hold the child’s hand, \\nshow him how to take his foot forward, walk yourself for a demonstration and so on, until \\nthe child learns to walk on his own.  \\nRegression  \\nSimilarly, in the case  of supervised learning, you give concrete known examples to the \\ncomputer. You say that for given feature value x1 the output is y1, for x2 it is y2, for x3 \\nit is y3, and so on. Based on this data, you let the computer figure out an empirical \\nrelationship between x and y.  \\nOnce the machine is trained in this way  with a sufficient number of data points, now you \\nwould ask the machine to predict Y for a given X. Assuming that you know the real value \\nof Y for this given X, you will be able to deduce whether the  machine’s prediction is correct . \\nThus, you will test whether the machine has learned by using the known test data. Once \\nyou are satisfied that the machine is able to do the predictions with a desired level of \\naccuracy (say 80 to 90%) you can stop further training the machine.  \\nNow, you can safely use the machine to do the predictions on unknown data points, or ask \\nthe machine to predict Y for a given X for which you do not know the real value of Y. This \\ntraining comes under the regression that we talked ab out earlier.  \\nClassification  \\nYou may also use machine learning techniques for classification problems. In classification \\nproblems, you classify objects of similar nature in to a single group. For example, in a set \\nof 100 students say, you may like to group them into three groups based on their heights \\n- short, medium and long. Measuring the height of each student, you will place them in a \\nproper group.  \\nNow, when a new student comes in, you will put him in an appropriate group by measuring \\nhis height. By fol lowing the principles in regression training, you will train the machine to \\nclassify a student based on his feature – the height. When the machine learns how the \\ngroups are formed, it will be able to classify any unknown new student correctly. Once \\nagain, you would use the test data to verify that the machine has learned your technique \\nof classification before putting the developed model in production.  \\nSupervised Learning is where the AI really began its journey. This technique was applied \\nsuccessfully in several cases. You have used this model while doing the hand -written \\nrecognition on your machine. Several algorithms have been developed for supervised \\nlearning. You will learn about them in the following chapters . ', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 10}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  8 \\n \\nUnsupervised Learning  \\nIn unsupervised le arning, we do not specify a target variable to the machine, rather we \\nask machine “What can you tell me about X?”. More specifically, we may ask questions \\nsuch as given a huge data set X, “What are the five best groups we can make out of X?” \\nor “What featu res occur together most frequently in X?”. To arrive at the answers to such \\nquestions, you can understand that the number of data points that the machine would \\nrequire to deduce a strategy would be very large. In case of supervised learning, the \\nmachine ca n be trained with even about few thousands of data points. However, in case \\nof unsupervised learning, the number of data points that is reasonably accepted for \\nlearning starts in a few millions. These days, the data is generally abundantly available. \\nThe d ata ideally requires curating. However, the amount of data that is continuously \\nflowing in a social area network, in most cases data curation is an impossible task.  \\n \\nThe following figure shows the boundary between the yellow and red dots as determined \\nby unsupervised machine learning. You can see it clearly that the machine would be able \\nto determine the class of each of the black dots with a fairly good accuracy.  \\n \\n \\nSource: \\nhttps://chrisjmccormick.files.wordpress.com/2013/08/approx_decision_boun\\ndary.png  \\n \\nThe unsupervised learning has shown a great success in many modern AI applic ations, \\nsuch as face detection, object detection, and so on.  \\n', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 11}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  9 \\n \\nReinforcement Learning  \\nConsider training a pet dog, we train our pet to bring a ball to us. We throw the ball at a \\ncertain distance and ask the dog to fetch it back to us. Every time the dog does this right, \\nwe reward the dog. Slowly, the dog learns that doing the job rightly gi ves him a reward \\nand then the dog starts doing the job right way every time in future. Exactly, this concept \\nis applied in “Reinforcement” type of learning. The technique was initially developed for \\nmachines to play games. The machine is given an algorithm  to analyze all possible moves \\nat each stage of the game. The machine may select one of the moves at random. If the \\nmove is right, the machine is rewarded, otherwise it may be penalized. Slowly, the \\nmachine will start differentiating between right and wron g moves and after several \\niterations would learn to solve the game puzzle with a better accuracy. The accuracy of \\nwinning the game would improve as the machine plays more and more games.  \\n \\nThe entire process may be depicted in the following diagram:  \\n \\n \\n \\nThis technique of machine learning differs from the supervised learning in that you need \\nnot supply the labelled input/output pairs. The focus is on finding the balance between \\nexploring the new solutions versus exploiting the learned solutions.  \\n', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 12}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  10 \\n \\nDeep Learn ing \\nThe deep learning is a model based on Artificial Neural Networks (ANN), more specifically \\nConvolutional Neural Networks (CNN)s. There are several architectures used in deep \\nlearning such as deep neural networks, deep belief networks, recurrent neural n etworks, \\nand convolutional neural networks.  \\nThese networks have been successfully applied in solving the problems of computer vision, \\nspeech recognition, natural language processing, bioinformatics, drug design, medical \\nimage analysis, and games. There ar e several other fields in which deep learning is \\nproactively applied. The deep learning requires huge processing power and humongous \\ndata, which is generally easily available these days.   \\nWe will talk about deep learning more in detail in the coming chapte rs. \\nDeep Reinforcement Learning  \\nThe Deep Reinforcement Learning (DRL) combines the techniques of both deep and \\nreinforcement learning. The reinforcement learning algorithms like Q -learning are now \\ncombined with deep learning to create a powerful DRL model . The technique has been with \\na great success in the fields of robotics, video games, finance and healthcare. Many \\npreviously unsolvable problems are now solved by creating DRL models. There is lots of \\nresearch going on in this area and this is very active ly pursued by the industries.  \\nSo far, you  have got a brief introduction to various machine learning models , now let us \\nexplore  slightly deeper into various algorithms that are available under these models.  \\n  ', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 13}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  11 \\n \\nSupervi sed learning is one of the important models of learning involved in training \\nmachines. This chapter talks in detail about the same.  \\nAlgorithms for Supervised Learning  \\nThere are several algorithms available for supervised learning. Some of the widely used \\nalgorithms of supervised learning are as shown below:  \\n \\n\\uf0b7 k-Nearest Neighbours  \\n\\uf0b7 Decision Trees  \\n\\uf0b7 Naive Bayes  \\n\\uf0b7 Logistic Regression  \\n\\uf0b7 Support Vector Machines  \\nAs we move ahead in this chapter, let us discuss in detail about each of the algorithms.  \\nk-Nearest Neighbours  \\nThe k -Nearest Neighbours, which is simply called kNN is a statistical technique that can \\nbe used for solving for classification and regression problems. Let us  discuss  the case of \\nclassifying an unknown object using kNN. Consider the distribution of object s as shown in \\nthe image given below : \\n \\n \\n \\nSource: \\nhttps://en.wikipedia.org/wiki/K -nearest_neighbors_algorithm  \\n 6. Machine Learning – Supervised Learning  \\n', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 14}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  12 \\n \\nThe diagram shows three types of objects, marked in red, blue and green colors. When \\nyou run the kNN  classifier on the above dataset, the boundaries for each type of object \\nwill be marked as shown below:  \\n \\n \\n \\nSource: \\nhttps://en.wikipedia.org/wiki/K -nearest_neighbors_algorithm  \\n \\nNow, consider a new unknown object that you want to classify as red, green or b lue. This \\nis depicted in the figure below.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 15}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  13 \\n \\nAs you see it visually, the unknown data point belongs to a class of blue objects. \\nMathematically, this can be concluded by measuring the distance of this unknown point \\nwith every other point in the data set. When you do so, you will know that most of its \\nneighbours are of blue color. The average distance to red and green objects would be \\ndefinitely more than the average distance to blue objects. Thus, this unknown object can \\nbe classified as belonging to blue class.   \\n \\nThe kNN algorithm can also be used fo r regression problems. The kNN algorithm is \\navailable as ready -to-use in most of the ML libraries.  \\nDecision Trees  \\nA simple decision tree in a flowchart format is shown below:  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nYou would write a code to classify your input data based on this flowchart. The flowchart \\nis self -explanatory and trivial. In this scenario, you are trying to classify an incoming email \\nto decide when to read it.  \\nIn reality, the decision trees can be larg e and complex. There are several algorithms \\navailable to create and traverse these trees. As a Machine Learning enthusiast , you need \\nto understand and master these techniques of creating and traversing decision trees.  \\n', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 16}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  14 \\n \\nNaive Bayes  \\nNaive Bayes is used for creating classifiers. Suppose you want to sort out (classify) fruits \\nof different kinds from a fruit basket. You may use features such as color, size and shape \\nof a fruit, For example, any fruit that is red in color, is round in shape and is about 10 cm \\nin diameter may be considered as Apple. So to train the model, you would use these \\nfeatures and test the probability that a given feature matches the desired constraints. The \\nprobabilities of different features are then combined to arrive at a probability th at a given \\nfruit is an Apple. Naive Bayes generally requires a small number of training data for \\nclassification.  \\nLogistic Regres sion \\nLook at the following diagram. It shows the distribution of data points in XY plane.  \\n \\n \\n \\nFrom the diagram, we can visuall y inspect the separation of red dots from green dots. You \\nmay draw a boundary line to separate out these dots. Now, to classify a new data point, \\nyou will just need to determine on which side of the line the point lies.  \\n', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 17}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  15 \\n \\nSupport Vector Machines  \\nLook at th e following distribution of data. Here the three classes of data cannot be linearly \\nseparated. The boundary curves are non -linear. In such a case , finding the equation of the \\ncurve becomes a complex job.  \\n \\n \\n \\nSource: http://uc -r.github.io/svm  \\n \\nThe Support Vector Machines (SVM) comes handy in determining the separation \\nboundaries in such situations.  \\n  \\n', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 18}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  16 \\n \\nFortunately, most of the time you do not have to code the algorithms mentioned in the \\nprevious lesson. T here are many standard libraries which provide the ready -to-use \\nimplementation of these algorithms. One such toolkit that is popularly used is scikit -learn. \\nThe figure below illustrates the kind of algorithms which are available for your use in this \\nlibrary.  \\n \\n \\n \\n \\nSource: https://scikit -learn.org/stable/tutorial/machine_learning_map/index.html  \\n \\nThe use of these algorithms is trivial and since these are well and field tested, you can \\nsafely use them in your AI applications. Most of these libraries are free to use even for \\ncommercial purposes.  \\n \\n \\n \\n \\n  7. Machine Learning – Scikit -learn Algorithm  \\n', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 19}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  17 \\n \\nSo far what you have seen is making the machine learn to find out the solution to our \\ntarget. In regression, we train the machine to predict a future value. In classification, we \\ntrain the machine to classify an unknown object in one of the categories defined by us. In \\nshort, we have been training machines so that it can predict Y for our data X. Given a huge \\ndata set and not estimating the categories, it would be difficult for us to train the machine \\nusing supervised learning. What if the machine can look up and analyze the big data \\nrunning into several Gigabytes and Terabytes and tell us that this data contains so many \\ndistinct categories?  \\nAs an example, consider the voter’s data. By considering some inputs from each voter \\n(these are called features in AI termin ology ), let the machine predict that there are so \\nmany voters who would vote for X political party and so many would vote for Y, and so \\non. Thus, in general, we are asking the machine given a huge set of data points X, “What \\ncan you tell me about X?”. Or i t may be a question like “What are the five best groups we \\ncan make out of X?”. Or it could be even like “What three features occur together most \\nfrequently in X?”.  \\n \\nThis is exactly the Unsupervised Learning is all about.   \\nAlgorithms for Unsupervised Lear ning \\nLet us now discuss one of the widely used algorithms for classification in unsupervised \\nmachine learning.  \\nk-means clustering  \\nThe 2000 and 2004 Presidential elections in the United States were close  — very close.  \\nThe largest percentage of the popular vote that any candidate received was 50.7%  and \\nthe lowest was 47.9%. If a percentage of the voters were to have switched sides,  the \\noutcome of the election would have been different. There are small groups of  voters who, \\nwhen properly appealed to, will swi tch sides. These groups may not be  huge, but with such \\nclose races, they may be big enough to change the outcome of  the election. How do you \\nfind these groups of people? How do you appeal to  them with a limited budget? The answer \\nis clustering.  \\nLet us unde rstand  how it  is done.  \\n\\uf0b7 First, you collect information on people either with or without their consent: any \\nsort of information that might give some clue about what is important to them and \\nwhat will influence how they vote.  \\n \\n \\n\\uf0b7 Then you put this information into some sort of clustering algorithm.  \\n 8. Machine Learning – Unsupervised Learning  ', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 20}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  18 \\n \\n\\uf0b7 Next, for each cluster (it would be smart to choose the largest one first) you craft \\na message that will appeal to these voters.  \\n \\n\\uf0b7 Finally, you deliver the campaign and measure to see if it’s working.  \\n \\nClustering is a type of unsupervised learning that automatically forms clusters of similar \\nthings. It is  like automatic classification. You can cluster almost anything, and the more \\nsimilar the items a re in the cluster, the better the  clusters are. In this chapter, we  are \\ngoing to study one type of clusteri ng algorithm called k -means. It i s called k -means \\nbecause it finds ‘k’ unique clusters, and the center of each cluster is the mean of the values \\nin that cluster.   \\nCluster Identification  \\nCluster identification tells an algorithm, “Here’s some data. Now group similar things \\ntogether and tell me about those groups.” The key difference from classification is that in \\nclassification  you know what you  are looking for. While that i s not the case in clustering.  \\nClustering is  sometimes called unsupervised classification because it produces the same \\nresult as classification does but without having predefined classes.  \\nNow, we are comfortable with both  supervised and unsupervised learning. To understa nd \\nthe rest of the machine learning categories, we must first understand Artificial Neural \\nNetworks (ANN) , which we will learn in the next chapter . \\n \\n  ', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 21}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  19 \\n \\nThe idea of artificial neural networks was derived from the  neural networks in the human \\nbrain. The human brain is really complex. Carefully studying the brain, the scientists and \\nengineers came up with an architecture that could fit in our digital world of binary \\ncomputers. One such typical architecture is shown in the diagram below:  \\n \\n \\n \\nThere is an input layer which has many sensors to collect data from the outside world. On \\nthe right hand side, we have an output layer that gives us the result predicted by the \\nnetwork. In between  these two , several layers are hidden. Each additional layer adds \\nfurther complexity in training the network, but would provide better results in most of the \\nsituations. There are several types of architectures designed which we will discuss now . \\n  9. Machine Learning – Artificial Neural Networks  \\n', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 22}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  20 \\n \\nANN Architectures  \\nThe diagram below shows several ANN architectures developed over a period of time and \\nare in practice today.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nSource: \\nhttps://towardsdatascience.com/the -mostly -complete -chart -of-neural -networks -explained -\\n3fb6f2367464  \\n \\n', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 23}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  21 \\n \\nEach architecture is developed for a specific type of application. Thus, when you use a \\nneural network for your machine learning application, you will have to use either one of \\nthe existing architecture or design your own. The type of application that you finally decide \\nupon depends on your application needs. There is no single guideline that tells you to use \\na specific network architecture.  \\n  ', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 24}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  22 \\n \\nDeep Learning uses ANN. First we will look at a few deep learning applications th at will \\ngive you an idea of its power.  \\nApplications  \\nDeep Learning has shown a lot of success in several areas of machine learning applications.  \\nSelf-driving Cars : The autonomous self -driving cars use deep learning techniques. They \\ngenerally adapt to the ever changing traffic situations and get better and better at driving \\nover a period of time.  \\nSpeech Recognition : Another interesting application of Deep Learning is speech \\nrecognition. All of us use several mobile apps today that are capable of recognizin g our \\nspeech. Apple’s Siri, Amazon’s Alexa, Microsoft’s Cortena and Google’s Assistant – all these \\nuse deep learning techniques.   \\nMobile Apps : We use several web -based and mobile apps for organizing  our photos. Face \\ndetection, face ID, face tagging, ident ifying objects in an image – all these use deep \\nlearning.  \\nUntapped Opportunities  of Deep Learning  \\nAfter looking at the great success deep learning applications have achieved in many \\ndomains, people started exploring other domains where machine learning wa s not so far \\napplied. There are several domains in which deep learning techniques are successfully \\napplied and there are many other domains which can be exploited. Some of these are \\ndiscussed here : \\n\\uf0b7 Agriculture is one such industry where people can apply  deep learning techniques \\nto improve the crop yield.  \\n \\n\\uf0b7 Consumer finance is another area where machine learning can greatly help in \\nproviding early detection on frauds and analyzing  customer’s ability to pay.  \\n \\n\\uf0b7 Deep learning techniques are also applied to t he field of medicine to create new \\ndrugs and provide a personalized prescription to a patient.  \\nThe possibilities are endless and one has to keep watching as the new ideas and \\ndevelopments pop up frequently.  \\n \\n 10. Machine Learning – Deep Learning  ', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 25}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  23 \\n \\nWhat is Required for Achieving More Using Deep L earning ? \\nTo use deep learning, supercomputing power  is a mandatory requirement. You need both \\nmemory as well as the CPU to develop deep learning models. Fortunately, today we have \\nan easy availability of HPC – High Performance Computing. Due to this,  the development \\nof the deep learning applications that we mentioned above became a reality today and in \\nthe future too we can see the applications in those untapped areas  that we discussed \\nearlier.  \\nNow, we will look at some of the limitations of deep lear ning that we must consider before \\nusing it in our machine learning application.  \\nDeep Learning - Disadvantages  \\nSome of the important points that you need to consider before using deep learning are \\nlisted below:  \\n\\uf0b7 Black Box approach  \\n\\uf0b7 Duration of Development  \\n\\uf0b7 Amount of Data  \\n\\uf0b7 Computationally Expensive  \\nWe will now study each one of these limitations in detail.  \\nBlack Box approach  \\nAn ANN is like a blackbox. You give it a certain input and it will provide you a specific \\noutput. The following diagram shows you one such application where you feed an animal \\nimage to a neural network and it tells you that the image is of a dog.  \\n \\nWhy this is called a black -box approach is that you do not know why the network came up \\nwith a certain result. You do not know how the network co ncluded that it is a dog? Now \\nconsider a banking application where the bank wants to decide the creditworthiness of a \\nclient. The network will definitely provide you an answer to this question. However, will \\nyou be able to justify it to a client? Banks nee d to explain it to their customers why the \\nloan is not sanctioned?  \\n', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 26}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  24 \\n \\nDuration of Development  \\nThe process of training a neural network is depicted in the diagram below:  \\n \\nYou first define the problem that you want to solve, create a specification for it, dec ide on \\nthe input features, design a network, deploy it and test the output. If the output is not as \\nexpected, take this as a feedback to restructure your network. This is an iterative process \\nand may require several iterations until the time network is ful ly trained to produce desired \\noutputs.  \\nAmount of Data  \\nThe deep learning networks usually require a huge amount of data for training, while the \\ntraditional machine learning algorithms can be used with a great success even with just a \\nfew thousands of data  points. Fortunately, the data abundance is growing at 40% per year \\nand CPU processing power is growing at 20% per year as seen in the diagram given below:  \\n \\n \\n', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 27}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  25 \\n \\nComputationally Expensive  \\nTraining a neural network requires several times more computational power than the one \\nrequired in running traditional algorithms. Successful training of deep Neural Networks \\nmay require several weeks of training time.  \\nIn contrast to this, traditional mac hine learning algorithms take only a few minutes/hours \\nto train. Also, the amount of computational power needed for training deep neural network \\nheavily depends on the size of your data and how deep and complex the network  is? \\nAfter having an overview of w hat Machine Learning  is, its capabilities, limitations, and \\napplications, let us now dive into learning “Machine Learning”.  \\n  ', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 28}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  26 \\n \\nMachine Learning has a very large width and requires skills across several domains.  The \\nskills that you need to acquire for becoming an expert in Machine Learning are listed below:  \\n \\n\\uf0b7 Statistics  \\n\\uf0b7 Probability Theories  \\n\\uf0b7 Calculus  \\n\\uf0b7 Optimization techniques  \\n\\uf0b7 Visualization  \\nNecessity of Various Skills of Machine Learning  \\nTo give you a brief idea of wh at skills you need to acquire, let us discuss some examples : \\nMathematical Notation  \\nMost of the machine learning algorithms are heavily based on mathematics. The level of \\nmathematics that you need to know is probably just a beginner level. What is important  \\nis that you should be able to read the notation that mathematicians use in their equations. \\nFor example - if you are able to read the notation and comprehend what it means, you \\nare ready for learning machine learning. If not, you may need to brush up your  \\nmathematics knowledge.  \\n \\n \\n \\n \\n \\n \\n 11. Machine Learning – Skills  for Machine \\nLearning  \\n', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 29}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  27 \\n \\nProbability Theory  \\nHere is an example to test your current knowledge of probability theory : Classifying with \\nconditional probabilities . \\n \\n \\n \\n \\n \\n \\nWith these definitions, we can define the Bayesian classification rule:  \\n\\uf0b7 If P(c1|x, y) > P(c 2|x, y) , the class is c 1 . \\n\\uf0b7 If P(c 1|x, y) < P(c 2|x, y) , the class is c 2 . \\nOptimization Problem  \\nHere is an optimization function  \\n \\n \\n \\n \\n \\nSubject to the following constraints:  \\n \\n \\n \\n \\n \\nIf you can read and understand the above, you are all set.  \\n', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 30}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  28 \\n \\nVisualization  \\nIn many cases, you will need to understand the various types of visualization plots to \\nunderstand your data distribution and interpret the results of the algorithm’s output.  \\n \\n \\n \\nBesides the above theoretical aspects of machine learning, you need good programming \\nskills to code those algorithms.  \\n \\nSo what does it take to implement ML?  Let us look into this in the next chapter.  \\n  \\n', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 31}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  29 \\n \\nTo develop ML applications, you will have to decide on the platform, the IDE and the \\nlanguage for development. There are several choices available. Most of these would meet \\nyour requirements easily as all of them provide the implementation of AI algorithms  \\ndiscussed so far.  \\nIf you are developing the ML algorithm on your own, the following aspects need to be  \\nunderstood carefully:  \\nThe language of your choice – this essentially is your proficiency in one of the languages \\nsupported in ML development.   \\nThe ID E that you use – This would depend on your familiarity with the existing IDEs and \\nyour comfort level.  \\nDevelopment platform – There are several platforms available for development and \\ndeployment. Most of these are free -to-use. In some cases, you may have t o incur a license \\nfee beyond a certain amount of usage. Here is a brief list of  choice of languages, IDEs and \\nplatforms for your ready reference.  \\nLanguage Choice  \\nHere is a list of languages that support ML development:  \\n\\uf0b7 Python  \\n\\uf0b7 R \\n\\uf0b7 Matlab  \\n\\uf0b7 Octave  \\n\\uf0b7 Julia \\n\\uf0b7 C++ \\n\\uf0b7 C \\nThis list is not essentially comprehensive; however, it covers many popular languages \\nused in machine learning development. Depending upon your comfort level, select a \\nlanguage for the development, develop your models and test.  \\nIDEs \\nHere is a list of IDEs which support ML development:  \\n\\uf0b7 R Studio  \\n\\uf0b7 Pycharm  \\n\\uf0b7 iPython/Jupyter Notebook  \\n 12. Machine Learning – Implementing  Machine \\nLearning  ', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 32}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  30 \\n \\n\\uf0b7 Julia \\n\\uf0b7 Spyder  \\n\\uf0b7 Anaconda  \\n\\uf0b7 Rodeo  \\n\\uf0b7 Google  –Colab   \\nThe above list is not essentially comprehensive. Each one has its own merits and demerits. \\nThe reader is encouraged to try out these different IDEs before narrowing down to a single \\none.  \\nPlatforms  \\nHere is a list of platforms on which ML applications can b e deployed : \\n \\n\\uf0b7 IBM  \\n\\uf0b7 Microsoft Azure  \\n\\uf0b7 Google Cloud  \\n\\uf0b7 Amazon  \\n\\uf0b7 Mlflow  \\n \\nOnce again this list is not exhaustive. The reader is encouraged to sign -up for the above -\\nmentioned services and try them out themselves.  \\n  ', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 33}),\n",
       " Document(page_content='Machine Learning   \\n \\n \\n  31 \\n \\nThis tutorial has introduced you to Machine Learning. Now, you know that Machine \\nLearning is a technique of training machines to perform the activities a human brain can \\ndo, albeit bit faster and better than an average human -being. Today we have seen that \\nthe machines can beat human champions in games such as Chess, AlphaGO, which are \\nconsidered very complex. You have seen that machines can be trained to perform human \\nactivities in several areas and can aid humans in living better lives.  \\nMachine Learning c an be a Supervised or Unsupervised. If you have lesser amount of data \\nand clearly labelled data for training, opt for Supervised Learning. Unsupervised Learning \\nwould generally give better performance and results for large data sets. If you have a \\nhuge dat a set easily available, go for deep learning techniques. You also have learned \\nReinforcement Learning and Deep Reinforcement Learning. You now know what Neural \\nNetworks  are, their applications and limitations.  \\nFinally, when it comes to the development of machine learning models of your own, you \\nlooked at the choices of various development languages, IDEs and Platforms. Next thing \\nthat you need to do is start learning and practicing each machine learning technique. The \\nsubject is vast, it means that there i s width, but if you consider the depth, each topic can \\nbe learned in a few hours. Each topic is independent of each other. You need to take into \\nconsideration one topic at a time, learn it, practice it and implement the algorithm/s in it \\nusing a language c hoice of yours. This is the best way to start studying Machine Learning. \\nPracticing one topic at a time, very soon you would acquire the width that is eventually \\nrequired of a Machine Learning expert.  \\nGood Luck!  13. Machine Learning – Conclusion   ', metadata={'source': 'machine_learning_tutorial.pdf', 'page': 34})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Mr. Narendra Damodardas Modi is the present and 15th Indian prime minister. He has been serving our nation since 26th May 2014. From the year 2001 to 2014, before taking over Delhi, he served the role of Honourable Chief Minister of Gujarat. He is a Member of the Parliament (MP), who represents the city of Varanasi. He is the leader of the popular Bharatiya Janata Party (BJP). \\n\\nIn the 2014 general election, BJP, led by Narendra Modi, gained the majority in the Lok Sabha. This was the first such major win for a political party since 1984.', metadata={'source': 'speech.txt'}),\n",
       " Document(page_content='In the 2014 general election, BJP, led by Narendra Modi, gained the majority in the Lok Sabha. This was the first such major win for a political party since 1984. \\n\\n\\nAll About Narendra Modi\\nEarly Life \\nPrime Minister Narendra Modi was born in a lower-middle-class family at Vadnagar, Gujarat. He had a keen interest in politics since the early days of his childhood. After completing his higher education in his hometown, he decided to join Rashtriya Swayamsevak Sangh. This is popularly known as RSS in our country. During his earlier ages of life, he was headstrong and was not that keen on the concept of marriage. Since then, he has dedicated his entire life to his motherland. At the age of 17, Narendra Modi decided to travel around the country and gain knowledge while helping others. Mr Modi is a great admirer of the ideologies of Swami Vivekananda.', metadata={'source': 'speech.txt'}),\n",
       " Document(page_content='He always emphasizes, \"Coming age is the age of knowledge. However, rich, poor, or powerful a country be, if they want to move ahead, only knowledge can lead them to that path.\" \\n\\n \\n\\nThe Life Story \\nNarendra Modi is a motivation for every Indian. He became the prime minister of India after breaking the bar of a poverty-stricken tea-selling boy. He has seamlessly become a development-oriented leader. Narendra Damodardas Modi was born on 17th September 1950. He is a prominent figure who showed us success is not related to the caste system. It doesn’t matter from where a person belongs or what his or her background is.', metadata={'source': 'speech.txt'}),\n",
       " Document(page_content='Narendra Modi is considered a master strategist and becomes a ray of hope for billions of lives in India. He is one of the leaders who stay focused on developments. With him, the dignity of labor is respected, and the working class is supported greatly. Narendra Modi is the glorious son of Late Damodardas Mulchand Modi and Heeraben Damodardas Modi. None of the prime ministers had taken office when their mother was alive. It is Mr. Modi who created history.', metadata={'source': 'speech.txt'}),\n",
       " Document(page_content='Eradicating Black Money from Our Country \\nDealing with strong hands, Narendra Modi has a significant role in eradicating black money from India. He demonetized the currency notes of 500 and 1000 rupees and later introduced a complete new semblance of Indian currency notes. This helped a lot in eliminating corruption, terrorism, and counterfeit currency from India. Our 15th Prime Minister is considered to be a stern administrator and leader with strict and protective discipline. These can be seen through his works, policies, speeches, and initiation of various schemes. He maintains a great image when it comes to rising from humble beginnings and moving to become the Prime Minister of India.', metadata={'source': 'speech.txt'})]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "documents=text_splitter.split_documents(text_documents)\n",
    "documents[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vector Embedding And Vector Store\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "db = Chroma.from_documents(documents,OpenAIEmbeddings())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Narendra Damodardas Modi is the present and 15th Indian prime minister. He has been serving our nation since 26th May 2014. From the year 2001 to 2014, before taking over Delhi, he served the role of Honourable Chief Minister of Gujarat. He is a Member of the Parliament (MP), who represents the city of Varanasi. He is the leader of the popular Bharatiya Janata Party (BJP). \n",
      "\n",
      "In the 2014 general election, BJP, led by Narendra Modi, gained the majority in the Lok Sabha. This was the first such major win for a political party since 1984.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"Who is Narendra Modi?\"\n",
    "retireved_results=db.similarity_search(query)\n",
    "print(retireved_results[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FAISS Vector Database\n",
    "from langchain_community.vectorstores import FAISS\n",
    "db1 = FAISS.from_documents(documents[:15], OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the 2014 general election, BJP, led by Narendra Modi, gained the majority in the Lok Sabha. This was the first such major win for a political party since 1984. \n",
      "\n",
      "\n",
      "All About Narendra Modi\n",
      "Early Life \n",
      "Prime Minister Narendra Modi was born in a lower-middle-class family at Vadnagar, Gujarat. He had a keen interest in politics since the early days of his childhood. After completing his higher education in his hometown, he decided to join Rashtriya Swayamsevak Sangh. This is popularly known as RSS in our country. During his earlier ages of life, he was headstrong and was not that keen on the concept of marriage. Since then, he has dedicated his entire life to his motherland. At the age of 17, Narendra Modi decided to travel around the country and gain knowledge while helping others. Mr Modi is a great admirer of the ideologies of Swami Vivekananda.\n"
     ]
    }
   ],
   "source": [
    "query = \"Where was Modi born?\"\n",
    "retireved_results=db1.similarity_search(query)\n",
    "print(retireved_results[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
